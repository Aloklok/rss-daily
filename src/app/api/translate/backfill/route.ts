/**
 * ç¿»è¯‘å›å¡« API ç«¯ç‚¹
 *
 * ç”± Vercel Cron æ¯å¤©è°ƒç”¨ï¼Œè‡ªåŠ¨ç¿»è¯‘å¤±è´¥çš„æ–‡ç« 
 * ä½¿ç”¨ HUNYUAN_TRANSLATION_MODELï¼ˆ--single æ¨¡å¼ï¼‰ç¡®ä¿ç¿»è¯‘è´¨é‡
 *
 * è°ƒåº¦ï¼šæ¯å¤© UTC 17:00 (åŒ—äº¬æ—¶é—´ 01:00)
 */
import { createClient } from '@supabase/supabase-js';
import { translateBatchAndSave } from '@/domains/intelligence/services/translate';
import { HUNYUAN_TRANSLATION_MODEL } from '@/domains/intelligence/constants';
import { NextRequest, NextResponse } from 'next/server';

// æ¯æ¬¡æœ€å¤šå¤„ç†çš„æ–‡ç« æ•°é‡ï¼ˆé¿å… Vercel 5 åˆ†é’Ÿè¶…æ—¶ï¼‰
const MAX_ARTICLES_PER_RUN = 10;

// Vercel Cron é…ç½®
export const maxDuration = 300; // 5 åˆ†é’Ÿ (Vercel Pro æœ€å¤§å€¼)

/**
 * é€’å½’è·å–æ‰€æœ‰ IDï¼Œçªç ´ Supabase 1000 æ¡é™åˆ¶
 */
async function fetchAllIds(
  supabase: any, // ä½¿ç”¨ any é¿å…å¤æ‚æ³›å‹é—®é¢˜
  tableName: string,
  hasSummary: boolean = false,
) {
  let allIds: { id: string | number }[] = [];
  let from = 0;
  const PAGE_SIZE = 1000;

  while (true) {
    let query = supabase
      .from(tableName)
      .select('id')
      .range(from, from + PAGE_SIZE - 1);

    if (hasSummary) {
      query = query.not('summary', 'is', null);
    }

    const { data, error } = await query;

    if (error) {
      console.error(`âŒ Failed to fetch IDs from ${tableName}:`, error);
      throw error;
    }

    if (!data || data.length === 0) break;

    allIds = allIds.concat(data);
    if (data.length < PAGE_SIZE) break;
    from += PAGE_SIZE;
  }

  return allIds;
}

export async function GET(req: NextRequest) {
  // 1. éªŒè¯ Cron è¯·æ±‚ (Vercel ä¼šå‘é€ CRON_SECRET header)
  const authHeader = req.headers.get('authorization');
  const cronSecret = process.env.CRON_SECRET;

  // å¦‚æœé…ç½®äº† CRON_SECRETï¼Œåˆ™éªŒè¯
  if (cronSecret && authHeader !== `Bearer ${cronSecret}`) {
    console.warn('[Backfill] Unauthorized request');
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  console.log('[Backfill] Starting translation backfill...');

  try {
    // 2. åˆå§‹åŒ– Supabase
    const supabase = createClient(
      process.env.SUPABASE_URL!,
      process.env.SUPABASE_SERVICE_ROLE_KEY!,
    );

    // 3. è·å–æ‰€æœ‰æ–‡ç«  ID è¿›è¡Œå·®é›†è®¡ç®—
    const [allIds, translatedIds] = await Promise.all([
      fetchAllIds(supabase, 'articles', true),
      fetchAllIds(supabase, 'articles_en'),
    ]);

    const allArticleIdList = allIds.map((r) => r.id);
    const translatedIdSet = new Set(translatedIds.map((r) => r.id));
    const untranslatedIds = allArticleIdList.filter((id) => !translatedIdSet.has(id));

    console.log(`[Backfill] Already translated: ${translatedIdSet.size}`);
    console.log(`[Backfill] Pending: ${untranslatedIds.length}`);

    if (untranslatedIds.length === 0) {
      return NextResponse.json({
        success: true,
        message: 'All articles already translated',
        stats: {
          total: allArticleIdList.length,
          translated: translatedIdSet.size,
          pending: 0,
          processed: 0,
        },
      });
    }

    // 4. è·å–å¾…ç¿»è¯‘æ–‡ç« å†…å®¹ï¼ˆé™åˆ¶æ•°é‡é¿å…è¶…æ—¶ï¼‰
    const idsToProcess = untranslatedIds.slice(0, MAX_ARTICLES_PER_RUN);
    const { data: articles, error: contentError } = await supabase
      .from('articles')
      .select(
        'id, title, category, summary, tldr, highlights, critiques, "marketTake", keywords, link, "sourceName", published, n8n_processing_date, verdict',
      )
      .in('id', idsToProcess)
      .order('published', { ascending: false });

    if (contentError) {
      console.error('[Backfill] Failed to fetch content:', contentError);
      return NextResponse.json({ error: 'Failed to fetch articles' }, { status: 500 });
    }

    if (!articles || articles.length === 0) {
      return NextResponse.json({
        success: true,
        message: 'No articles to process',
        stats: { processed: 0, pending: untranslatedIds.length },
      });
    }

    // 5. é€ç¯‡ç¿»è¯‘ï¼ˆä½¿ç”¨ HUNYUAN_TRANSLATION_MODELï¼Œå³ --single æ¨¡å¼ï¼‰
    let successCount = 0;
    let failedCount = 0;

    for (const article of articles) {
      const chunk = [
        {
          id: String(article.id),
          title: article.title || '',
          category: article.category || '',
          summary: article.summary || '',
          tldr: article.tldr || '',
          highlights: article.highlights || '',
          critiques: article.critiques || '',
          marketTake: article.marketTake || '',
          keywords: Array.isArray(article.keywords) ? article.keywords : [],
          link: article.link,
          sourceName: article.sourceName,
          published: article.published,
          n8n_processing_date: article.n8n_processing_date,
          verdict: article.verdict,
        },
      ];

      try {
        const result = await translateBatchAndSave(chunk, HUNYUAN_TRANSLATION_MODEL);
        if (result.success) {
          successCount += result.count;
          console.log(`[Backfill] âœ… Translated article ${article.id}`);
        } else {
          failedCount++;
          console.error(`[Backfill] âŒ Failed article ${article.id}: ${result.error}`);
        }
      } catch (e: any) {
        failedCount++;
        console.error(`[Backfill] ğŸ’¥ Error article ${article.id}: ${e.message}`);
      }
    }

    const remainingCount = untranslatedIds.length - successCount;

    console.log(`[Backfill] Completed: ${successCount} success, ${failedCount} failed`);
    console.log(`[Backfill] Remaining: ${remainingCount}`);

    return NextResponse.json({
      success: true,
      message: `Processed ${articles.length} articles`,
      stats: {
        total: allArticleIdList.length,
        translated: translatedIdSet.size + successCount,
        pending: remainingCount,
        processed: articles.length,
        success: successCount,
        failed: failedCount,
      },
    });
  } catch (e: any) {
    console.error('[Backfill] Fatal error:', e.message);
    return NextResponse.json({ error: e.message }, { status: 500 });
  }
}
