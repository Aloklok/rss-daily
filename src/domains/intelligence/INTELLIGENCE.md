# AI 智能体架构文档 (AI.md)

本项目集成了一套基于 **RAG (Retrieval-Augmented Generation)** 模式的高级 AI 对话系统，旨在为管理员提供基于本地简报和行业时事的智能问答能力。

## 🏗 核心架构 (RAG 2.0 流路)

系统的执行链路分为三个阶段：

### 0. 向量化 (Vectorization)

在进入 RAG 流程前，所有文章均通过 `src/lib/server/embeddings.ts` (供脚本使用) 或 `src/lib/server/gemini.ts` 进行向量化预处理。我们采用**混合语义指纹**策略，而非单纯的正文切片。

- **Embedding 模型**: `gemini-embedding-001`
- **向量化字段**: `title` + `category` + `keywords` + `summary` + `tldr`
- **逻辑**: 通过将分类和关键词硬编码进向量内容，确保了语义搜索时不仅能匹配到内容相似，还能匹配到“分类正确”的文章，大幅提升召回准确率。
- **现状**: 向量生成在 API 层支持多 Key 独立调用，`ai` 目的的请求强制使用 `CHENG30` 账号。

### 1. 意图识别与路由 (Intelligence Routing)

在进入 RAG 链路前，系统会通过 **AI Router** (基于 Gemini 1.5 Flash) 对用户提问进行意图分类：

- **RAG_LOCAL**: 识别到用户在咨询特定资讯或本地文章。执行完整的“向量检索 + 重排”链路。
- **DIRECT (闲聊模式)**: 用户显式开启“闲聊”开关或提问属于通用知识。系统会跳过数据库检索，以低延迟直接回答。
- **SEARCH_WEB**: 识别到需要最新非本地资讯。自动开启 Google Search Grounding 联网搜索。

### 2. 召回阶段 (Recall Phase)

为了平衡召回率与引用的精确度，系统采用两阶段过滤：

- **第一阶段（混合检索 Hybrid Search）**：
  - 系统采用 **5 层优先级分权排序 (Multi-level Priority)**，综合词面匹配 (`ILIKE`)、索引检索 (`&@~`) 与向量空间算法：
    - **P1 (最高: 原文匹配)**: 标题字符串字面包含 (`ILIKE`)。专门为“复制标题搜索”设计，确保精准命中。
    - **P2 (高: 标题核心)**: 标题关键词命中 (`&@~`) 或 向量强相关 (`Similarity > 0.88`)。
    - **P3 (中: 标签特征)**: 关键词字段 (`keywords`) 或 分类 (`category`) 命中。
    - **P4 (低: 摘要噪音)**: 文章摘要 (`summary`) 命中。将其降级是为了防止摘要中的冗余词汇遮挡标题精准匹配的结果。
    - **P5 (兜底: 语义)**: 满足基础语义门槛 (`Similarity > 0.60`) 的其它关联文章。
- **第二阶段（精选/重排）**：
  - **输入**: 将 Top 50 篇的 `id, title, published, sourceName, summary, category, keywords` 组装为 Prompt。
  - **交互**: 调用 Gemini (2.0 Flash) 执行语义重排 (`reRankArticles`)。
  - **逻辑**: 模型基于 User Query 剔除内容重复或时效性差的篇目。
  - **结果**: 选出最相关的 **Top 10-15** 篇作为最终上下文。这极大降低了模型的“注意力发散”，提高了引用的准确度。

### 2. 增强上下文生成 (Context Enrichment)

在精选出 Top 15 后，系统会构建一个高度浓缩的背景列表供模型处理：

- **字段提取**: 从数据库中提取以下核心元数据：
  - **基础**: `id`, `title`, `published`, `link`, `sourceName`
  - **分类**: `category`, `keywords`
  - **摘要**: `tldr` (一句话总结), `summary`
  - **深度分析**: `verdict` (评分与重要性), `highlights` (技术亮点), `critiques` (犀利吐槽), `marketTake` (市场观点)
- **注入 Persona**: 注入“首席架构师” Persona，强制执行差异化引用逻辑（见下文）。

### 3. 流式渲染与交互 (Streaming & UX)

- **SSE 流式输出**：通过 Server-Sent Events 实现毫秒级响应，并配合缓冲区解决数据包截断问题。
- **交互渲染引擎**：前端通过深度递归解析 Markdown，将文本中的 `[N]` 自动转化为交互组件。
  - **多格式识别**: 采用增强正则表达式，支持 `[1]`、`[1.1]`、`¹` 等多种角标变体。
  - **加粗兼容**: 解决了角标在 `**加粗文本**` 内部时无法被点击的问题。
  - **点击行为**: 点击后不再打开外部链接，而是直接触发 `UnifiedArticleModal` 并默认进入“简报”视图。对于未缓存的文章，系统会自动触发异步补全（Hydration）流程。

---

## 🔍 引用准则 (Citation Rules)

为了确保专业度，系统遵循以下“差异化引用”策略：

- **常识不引**：互联网通用知识、基础概念不添加脚注。
- **证据必引**：涉及具体数据、特定项目案例、独到见解时，强制在句末标注 `[N]`。
- **透明审计**：每条回复末尾均有 `[统计：检索 X 篇，引用了 Y 篇]`，方便管理员溯源。

---

## ⚙️ 模型与配额管理

- **模型锁定策略 (Version Locking)**：2026 年起，Google 调整了 `latest` 别名的指向（通常指向配额极紧的 2.5 系列）。为保证稳定性，系统已**禁用自动升级/纠偏逻辑**，强制锁定使用 `gemini-1.5-flash`、`gemini-2.0-flash` 等具体的稳定版本 ID。
- **多账号独立管理 (Account Independence)**：
  - **Key 隔离**: 系统集成 `ALOK` 和 `CHENG30` 两个独立配额的账号。
  - **无回退原则 (No-Fallback)**: 为确保使用透明，系统**禁用了账号自动切换逻辑**。如果所选账号配额超限，将直接报错并提示，避免管理员在不知情的情况下跨账号消耗。
  - **识别后缀**: 模型选择器中通过 `@alok` 或 `@cheng30` 后缀明确指定调用账号。
- **“羊毛”配额池 (Quota Buffering)**：对话框型号选择器集成了多个具备独立配额权重的模型。当主模型触发 429 报错时，管理员可通过切换“独立池子”型号实现每日可用次数的最大化。
- **使用看板**：对话框型号选择器中实时显示模型配额（RPM/RPD）及“独立池子”标识，辅助决策。

---

## ⚠️ 开发注意事项 (Important Notes)

### 1. 渲染性能与 VDOM 稳定性

- **递归解析**: 系统的引用按钮采用深度递归解析方案。虽然功能强大（支持嵌套在加粗/斜体内），但计算效率受对话长度影响。
- **对话锁定**: `ChatStore` 会根据记忆窗口（默认 8 轮）自动管理。如需更长历史，需在 `src/domains/intelligence/store/chatStore.ts` 中调整以平衡内存与性能。
- **组件持久化 (Critical)**:
  - **组件隔离**: `MessageList` 已被抽离为独立的 `React.memo` 组件，确保在流式输出（Partial Streaming）触发高频重绘时，只有最后一条消息在更新，上百条历史消息保持静态。这是防止多轮对话 CPU 飙升的关键。
  - **顶层声明**: `ChatMessageItem` 和 `MessageList` 必须声明在 **顶层作用域**（即模态框主组件外部）。严禁在 `src/domains/intelligence/components/AIChatModal.tsx` 内部动态声明组件，否则 React 每次 Render 都会认为其是新组件，强制卸载旧 DOM 并重新挂载，这将使 `React.memo` 完全失效并导致剧烈卡顿。

### 2. 模型配额与 API 隔离

- **物理隔离**: 为防止实时问答与后台定时任务（如大规模简报生成）争抢配额，AI 助手强制锁定使用 `GOOGLE_GENERATIVE_AI_API_KEY_CHENG30`。
- **模型路由**: 在 `app/api/ai/chat/route.ts` 中维护。严禁在后端再次开启“自动别名转换”，必须保留前端透传的特定版本 ID 以维护配额隔离。

### 3. 样式保护与视觉架构

- **Prose 作用域**: 消息内容强制包裹在 `.prose` 类中。修改全局样式时，应优先使用 Tailwind 的 `prose-xxx` 工具类或通过 `globals.css` 中针对 AI 容器的定向选择器来调整，避免全局样式污染。
- **模糊度设计 (Blur Rationale)**: 模态框背景模糊度限制在 `backdrop-blur-xl`。实测表明，在流式打字高频刷新时，`2xl` 或更高强度的 GPU 高斯模糊计算会与文字渲染产生资源竞争，导致明显的低帧率感。

---

## 🚀 深度工程优化建议 (Optimization Suggestions)

基于当前版本的交付质量与用户反馈，以下是下一步建议的工程优化方向：

### 1. 架构组件化重构 (Code Modularization)

- **现状**: `AIChatModal.tsx` 已膨胀至 700+ 行，逻辑高度耦合。
- **建议**: 将其拆分为 `ChatHeader`、`MessageList`、`MessageItem`、`CitationPanel`、`ModelSelector` 和 `ChatInput`。
- **收益**: 提高组件的可维护性，并通过 React.memo 进一步精简重绘范围，提升流畅度。

### 2. 语义缓存层 (Semantic Caching)

- **建议**: 在 `app/api/ai/chat/route.ts` 中引入语义缓存。
- **逻辑**: 对用户的 Query 进行向量化，如果与 10 分钟内已回答过的 Query 相似度高于 0.98，则直接返回缓存结果。
- **收益**: 极大减少 Gemini 配额消耗，实现“秒回”体验。

### 3. 引用系统的极致鲁棒性 (Citation Robustness)

- **多格式兼容**: 采用统一的 `getOriginalIndex` 辅助函数，确保 `[1]`、`[ 1 ]`、`¹` 等各种 AI 可能输出的变体都能被精准捕获。
- **后置修正机制**: 在数据持久化前端增加“自动校准”逻辑，纠正 AI 自报的统计数字与实际提取到的文献数量之间的差异。
- **首次出现原则**: 实施“每个引用仅在正文首次出现时转为角标”的策略，减少视觉干扰，保持排版轻盈。

### 4. 样式与性能的平衡 (Style vs. Perf)

- **纯色优先**: 为了极致的流式打字性能，在全屏模式下应优先使用纯色背景（去除 `backdrop-blur`），避免 GPU 重绘与文字渲染争抢资源。
- **全屏自适应**: 模态框应支持“真全屏”切换（Edge-to-Edge），但在宽屏设备上必须通过 `max-w-5xl` 限制对话气泡宽度，保护阅读体验。

---

## 📅 路线图 (Roadmap)

1. **[待办] 混合搜索深度集成**：接入 Serper 或 Bing API，弥补 Google Search Grounding 在特定中文垂直领域的信息差。
2. **[进行中] 对话状态完全持久化**：确保元数据（Metadata）随消息体一同落库，彻底解决页面刷新后历史引用失效的问题。
3. **[计划] 智能搜索触发器**：根据本地检索文章的相关度评分，自动决定是否静默开启联网搜索。
4. **[计划] 多模态支持**：基于 Gemini 2.0 Pro 能力，支持管理员直接拖入截图让 AI 分析报表。

### 5. 高级检索策略 (Search Intelligence)

- **[已完成] 关键词搜索升级**: 已将 RPC 升级为 **PGroonga** (`&@~`) + **字面加权门槛**。通过一套 5 级优先级矩阵 (P1-P5)，解决了“标题复制搜不到”的痛点，确保字面匹配、标签匹配与语义匹配在不同维度的有机融合。
- **[已完成] 智能路由 (AI Router)**: 在 RAG 链路上游引入轻量级路由层 (Gemini 1.5 Flash)，负责：
  - **意图识别**: 区分“闲聊 (Small Talk)”、“普通搜索 (RAG)”和“联网搜索 (Web Search)”。
  - **参数提取**: 将自然语言（如“上周高分文章”）转化为结构化引导条件。
  - **性能收益**: 对非检索类问题（如“你好”、“你是谁”）实现极速秒回。

### 6. 异步任务架构 (Scalability)

- **[架构建议] 引入 PGMQ**: 当前系统采用同步生成 Embedding，适合单条数据流。若未来扩展至**批量抓取**场景（如一次导入 500 篇），强烈建议引入 `pgmq`（Supabase 扩展）：
  - **流程**: 爬虫入库 -> 写入 PGMQ 队列 -> Worker 消费队列 -> 调用 Gemini 生成向量 -> 异步回写 DB。
  - **收益**: 解耦 AI 处理的长耗时（5s+）与入库的短耗时（ms级），防止 API 超时。

---

## 🛠 如果您是 Prompt 工程师 (Operations)

为了支持 Prompt 的快速迭代与版本回滚，项目内置了以下工程化脚本：

### 1. 拉取最新 Prompt (`pull`)

将线上的 Prompt 配置同步到本地 `CHAT_PROMPT.MD` 文件中。

```bash
pnpm chat-prompt:pull
```

### 2. 推送 Prompt 更新 (`push`)

将本地 `CHAT_PROMPT.MD` 的修改推送到 Supabase 生产环境。

**常规更新（覆盖模式）**：
适用于微调错别字或小优化，不改变 Key。

```bash
pnpm chat-prompt:push
```

**版本迭代（备份模式）**：
适用于重大逻辑变更。该命令会自动将线上当前的 Prompt 备份为 `gemini_chat_prompt_YYYYMMDD`，然后再覆盖写入新版。

```bash
pnpm chat-prompt:push --new
```

---

## 7. 简报生成策略 (Briefing Generation)

简报生成是 Intelligence 领域的核心能力，通过调用 Gemini 将原始 HTML 转化为结构化洞察。

### 7.1 生成模式差异

系统支持两种生成模式，它们在**日期处理**上遵循相同的原则：

| 模式 | 场景 | 并发策略 | 日期逻辑 | 缓存清除范围 |
| :--- | :--- | :--- | :--- | :--- |
| **单篇生成** | 用户点击"重新生成" | 串行 | 严格保留原日期 | 详情页 + 日期页 + 首页(若为今日) |
| **批量生成** | 管理员后台批量操作 | 伪并发 (Batch Payload) | 严格保留原日期 | 日期页 + **首页(若含今日)** + 数据标签 |

### 7.2 缓存一致性 (Cache Consistency)

为了确保 AI 生成的内容能即时反映在前端，生成动作（Action）必须执行**全链路缓存清除**：

1.  **数据层 (`unstable_cache`)**: 必须通过 `revalidateTag('briefing-data-${date}')` 清除，否则服务端组件仍会读取旧数据。
2.  **页面层 (ISR)**: 必须清除 `/date/${date}`。
3.  **首页联动**: 若生成的文章归属于“今天（上海时间）”，**必须**额外清除首页 `/` 缓存。这是因为首页采用了“强制今日”的 SSR 策略，若不清除，用户访问首页时将看不到最新的 AI 分析结果。

> **注意**: 批量生成动作 (`generateBulkBriefingAction`) 已内置了上述所有清除逻辑，确保了“一键生成，全站更新”。
